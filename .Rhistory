testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(testData1$Exterior1st=="Other","VinylSd",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)
testData1$SalePrice = predict(custom.model,testData1)
summary(testData1)
str(testData1)
#Load in testing data and fill in the missing data in the same manner
testData = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/test.csv",header = TRUE)
testData$MSSubClass = ifelse(testData$MSSubClass==150,180,testData$MSSubClass)
testData$FullBath = ifelse(testData$FullBath==4,3,testData$FullBath)
testData$Fireplaces = ifelse(testData$Fireplaces==4,3,testData$Fireplaces)
#Convert certain variables into factors
cols.to.factor = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities",
"LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType",
"HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st",
"Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual",
"BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC",
"CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType",
"GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature",
"SaleType","SaleCondition","PoolArea","MoSold","YrSold","Fireplaces","FullBath")
testData[cols.to.factor] = lapply(testData[cols.to.factor],factor)
testData$PoolYN = ifelse(is.na(testData$PoolQC),"NO","YES")
testData$PoolYN = as.factor(testData$PoolYN)
#Testing test set
testData1 = testData %>%
dplyr::select(Id,MSSubClass, MSZoning,LotArea,LotConfig, Neighborhood, Condition2,
BldgType, Neighborhood, OverallQual, YearBuilt,YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd,
MasVnrType, MasVnrArea, ExterQual, Foundation, BsmtQual, BsmtFinType1, TotalBsmtSF,
Heating, HeatingQC, CentralAir,Electrical,
X1stFlrSF, X2ndFlrSF, LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,
BedroomAbvGr, KitchenAbvGr, KitchenQual,TotRmsAbvGrd,
Fireplaces,GarageCars,GarageArea,
PavedDrive, WoodDeckSF, OpenPorchSF,X3SsnPorch,ScreenPorch,
PoolYN, MoSold,YrSold)
testData1$GrLivArea = log(testData1$GrLivArea)
summary(testData1)
#Adjusting NA factors
testData1$MSZoning = as.character(testData1$MSZoning)
testData1$MSZoning = ifelse(is.na(testData1$MSZoning),"RL",testData1$MSZoning)
testData1$MSZoning = as.factor(testData1$MSZoning)
testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(is.na(testData1$Exterior1st),"Other",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)
testData1$Exterior2nd = as.character(testData1$Exterior2nd)
testData1$Exterior2nd = ifelse(is.na(testData1$Exterior2nd),"Other",testData1$Exterior2nd)
testData1$Exterior2nd = as.factor(testData1$Exterior2nd)
testData1$BsmtQual = as.character(testData1$BsmtQual)
testData1$BsmtQual = ifelse(is.na(testData1$BsmtQual),"TA",testData1$BsmtQual)
testData1$BsmtQual = as.factor(testData1$BsmtQual)
testData1$BsmtFinType1 = as.character(testData1$BsmtFinType1)
testData1$BsmtFinType1 = ifelse(is.na(testData1$BsmtFinType1),"Unf",testData1$BsmtFinType1)
testData1$BsmtFinType1 = as.factor(testData1$BsmtFinType1)
testData1$KitchenQual = as.character(testData1$KitchenQual)
testData1$KitchenQual = ifelse(is.na(testData1$KitchenQual),"TA",testData1$KitchenQual)
testData1$KitchenQual = as.factor(testData1$KitchenQual)
testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(testData1$Exterior1st=="Other","VinylSd",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)
testData1$SalePrice = predict(custom.model,testData1)
summary(testData1)
testData1$MasVnrType = as.character(testData1$MasVnrType)
testData1$MasVnrType = ifelse(is.na(testData1$MasVnrType),"None",testData1$MasVnrType)
testData1$MasVnrType = as.factor(testData1$MasVnrType)
#Load in testing data and fill in the missing data in the same manner
testData = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/test.csv",header = TRUE)
testData$MSSubClass = ifelse(testData$MSSubClass==150,180,testData$MSSubClass)
testData$FullBath = ifelse(testData$FullBath==4,3,testData$FullBath)
testData$Fireplaces = ifelse(testData$Fireplaces==4,3,testData$Fireplaces)
testData$MasVnrArea = ifelse(is.na(testData$MasVnrArea),0,testData$MasVnrArea)
testData$TotalBsmtSF = ifelse(is.na(testData$TotalBsmtSF),0,testData$TotalBsmtSF)
testData$BsmtFullBath = ifelse(is.na(testData$BsmtFullBath),0,testData$BsmtFullBath)
testData$BsmtHalfBath = ifelse(is.na(testData$BsmtHalfBath),0,testData$BsmtHalfBath)
testData$GarageCars = ifelse(is.na(testData$GarageCars),0,testData$GarageCars)
testData$GarageArea = ifelse(is.na(testData$GarageArea),0,testData$GarageArea)
testData[cols.to.factor] = lapply(testData[cols.to.factor],factor)
testData$PoolYN = ifelse(is.na(testData$PoolQC),"NO","YES")
testData$PoolYN = as.factor(testData$PoolYN)
#Testing test set
testData1 = testData %>%
dplyr::select(Id,MSSubClass, MSZoning,LotArea,LotConfig, Neighborhood, Condition2,
BldgType, Neighborhood, OverallQual, YearBuilt,YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd,
MasVnrType, MasVnrArea, ExterQual, Foundation, BsmtQual, BsmtFinType1, TotalBsmtSF,
Heating, HeatingQC, CentralAir,Electrical,
X1stFlrSF, X2ndFlrSF, LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,
BedroomAbvGr, KitchenAbvGr, KitchenQual,TotRmsAbvGrd,
Fireplaces,GarageCars,GarageArea,
PavedDrive, WoodDeckSF, OpenPorchSF,X3SsnPorch,ScreenPorch,
PoolYN, MoSold,YrSold)
testData1$GrLivArea = log(testData1$GrLivArea)
#Adjusting NA factors
testData1$MSZoning = as.character(testData1$MSZoning)
testData1$MSZoning = ifelse(is.na(testData1$MSZoning),"RL",testData1$MSZoning)
testData1$MSZoning = as.factor(testData1$MSZoning)
testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(is.na(testData1$Exterior1st),"Other",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)
testData1$Exterior2nd = as.character(testData1$Exterior2nd)
testData1$Exterior2nd = ifelse(is.na(testData1$Exterior2nd),"Other",testData1$Exterior2nd)
testData1$Exterior2nd = as.factor(testData1$Exterior2nd)
testData1$BsmtQual = as.character(testData1$BsmtQual)
testData1$BsmtQual = ifelse(is.na(testData1$BsmtQual),"TA",testData1$BsmtQual)
testData1$BsmtQual = as.factor(testData1$BsmtQual)
testData1$BsmtFinType1 = as.character(testData1$BsmtFinType1)
testData1$BsmtFinType1 = ifelse(is.na(testData1$BsmtFinType1),"Unf",testData1$BsmtFinType1)
testData1$BsmtFinType1 = as.factor(testData1$BsmtFinType1)
testData1$KitchenQual = as.character(testData1$KitchenQual)
testData1$KitchenQual = ifelse(is.na(testData1$KitchenQual),"TA",testData1$KitchenQual)
testData1$KitchenQual = as.factor(testData1$KitchenQual)
testData1$MasVnrType = as.character(testData1$MasVnrType)
testData1$MasVnrType = ifelse(is.na(testData1$MasVnrType),"None",testData1$MasVnrType)
testData1$MasVnrType = as.factor(testData1$MasVnrType)
testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(testData1$Exterior1st=="Other","VinylSd",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)
summary(testData1)
testData1$SalePrice = predict(custom.model,testData1)
testData1$SalePrice = exp(testData1$SalePrice)
cumstom.result = testData1 %>% dplyr::select(Id,SalePrice)
head(custom.result)
custom.result = testData1 %>% dplyr::select(Id,SalePrice)
head(custom.result)
write.csv(custom.result,"custom_model_Miller_YU.csv",row.names = FALSE)
variables.used
set.seed(116)
#create forward fit model
#write a program to generate 5 different combination to test forward selection model
iterations = 5
splitPerc = 0.9
total_RMSE = 0
for(i in 1:iterations){
print(i)
trainIndices = sample(1:dim(variables.used)[1],round(splitPerc * dim(variables.used)[1]))
train = variables.used[trainIndices,]
test = variables.used[-trainIndices,]
forward_fit = lm(lSalePrice~.-Id,data=train)
forward.model = ols_step_forward_aic(forward_fit,penter=0.15)
prediction = predict(forward.model$model,test)
squared_MSPE = mean((test$lSalePrice - prediction)^2)
temp_RMSE = sqrt(squared_MSPE)
total_RMSE = total_RMSE+temp_RMSE
}
#total RMSE = 0.1235978...
total_RMSE/iterations
library(tidyverse)
library(ggplot2)
library(olsrr)
library(GGally)
library(caret)
library(MASS)
library(leaps)
#Load in Dataset
#Call original data amesHouse
amesHouse = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/train.csv",header = TRUE)
#extract variables we're interested for Analysis 1
data1 = amesHouse %>% dplyr::select(SalePrice,GrLivArea,Neighborhood)%>%
filter(Neighborhood=="NAmes"|Neighborhood=="Edwards"|Neighborhood=="BrkSide")
#383 observations selected after filtering neighborhood of "NAmes", "Edwards" and "BrkSide"
#Convert Neighborhood to factors
data1$Neighborhood = as.factor(data1$Neighborhood)
#Plot and observe the relationship between SalePrice and GrLivArea
data1 %>% ggplot(aes(x=GrLivArea,y=SalePrice))+
geom_point()+ggtitle("Sale Price vs. Square Foot of Living area")+
xlab("Square Foot of Living Area")+
ylab("Sale Price")
#there are some outliers that may not have come from the same population of interest
#build model to identify the outliers
model1 = lm(SalePrice~GrLivArea,data=data1)
ols_plot_cooksd_bar(model1)
ols_plot_resid_stand(model1)
#Look at residual plots and cook's distance
plot(model1)
summary(model1)
#build new model to double check
model2 = lm(SalePrice~GrLivArea,data=data2)
ols_plot_cooksd_bar(model2)
#ols_plot_resid_lev(model1)
# Observation 339 has cook's distance larger than 5.6, Observation 131's cook's D is larger than 1 so it may due to the face it is a unique case.
# Observation 169 and 190 has standarlized residual greater than 4, these two observations can also potentially not coming from the same population of interest
# Since our sample is sufficiently large, deleting these four outliers won't make a huge difference.
# Call these new dataset without outliers data2
data2 = data1[-c(131,169,190,339),]
#build new model to double check
model2 = lm(SalePrice~GrLivArea,data=data2)
ols_plot_resid_stand(model2)
ols_plot_cooksd_bar(model3)
ols_plot_cooksd_bar(model2)
plot(model3)
plot(model2)
xlab("Square Foot of Living Area")+
ylab("Sale Price")
data2 %>% ggplot(aes(x=GrLivArea,y=SalePrice))+
geom_point()+ggtitle("Sale Price vs. Square Foot of Living area")+
xlab("Square Foot of Living Area")+
ylab("Sale Price")
#Cook's Distance within roughly 0.1, residual within 3, decent amount of observations beyond 2 (within 5%)
#Assumptions met, move on to include categorical variables
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
summary(model3)
plot(model3)
data2 %>% ggplot(aes(x=GrLivArea,y=SalePrice,color=Neighborhood))+
geom_point()+ggtitle("Sale Price vs. Square Foot of Living area")+
xlab("Square Foot of Living Area")+
ylab("Sale Price")
plot(model3)
ols_plot_resid_stand(model3)
ols_plot_cooksd_bar(model3)
m
summary(model3)
summary(model2)
anova(model3)
confint(model3)
summary(model3)
data2$Neighborhood = relevel(data2$Neighborhood,ref="Edwards")
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
summary(model3)
confint(model3)
# Change reference to BrkSide to get CI for slope
data2$Neighborhood = relevel(data2$Neighborhood,ref="BrkSide")
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
summary(model3)
confint(model3)
# Change reference to NAmes to get CI for slope
data2$Neighborhood = relevel(data2$Neighborhood,ref="NAmes")
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
summary(model3)
confint(model3)
# convert certain columns we need into factor in order to use multi regression model
cols.to.factor = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities",
"LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType",
"HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st",
"Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual",
"BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC",
"CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType",
"GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature",
"SaleType","SaleCondition","PoolArea","MoSold","YrSold","Fireplaces","FullBath")
amesHouse[cols.to.factor] = lapply(amesHouse[cols.to.factor],factor)
#Now exploring relationships between continuous variables
amesHouse %>% dplyr::select(SalePrice,LotFrontage,LotArea,YearBuilt,YearRemodAdd,MasVnrArea,BsmtFinSF1,BsmtFinSF2)%>%
ggpairs()
#Try Logrithmic on SalePrice
amesHouse$lSalePrice = log(amesHouse$SalePrice)
#explore relationship between log SalePrice
amesHouse %>% dplyr::select(lSalePrice,LotFrontage,LotArea,YearBuilt,YearRemodAdd,MasVnrArea,BsmtFinSF1,BsmtFinSF2)%>%
ggpairs()
#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtUnfSF,TotalBsmtSF,X1stFlrSF,X2ndFlrSF,LowQualFinSF,GrLivArea) %>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtUnfSF,TotalBsmtSF,X1stFlrSF,X2ndFlrSF,LowQualFinSF,GrLivArea) %>%
ggpairs()
#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
TotRmsAbvGrd)%>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtUnfSF,TotalBsmtSF,X1stFlrSF,X2ndFlrSF,LowQualFinSF,GrLivArea) %>%
ggpairs()
#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
TotRmsAbvGrd)%>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
TotRmsAbvGrd)%>%
ggpairs()
#The only variable seem to have good correlation with lSalePrice is FullBath,TotRmsAbvGrd.
#???If we should change BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr to factors???
#Keep going
amesHouse %>% dplyr::select(SalePrice,GarageYrBlt,GarageCars,GarageArea) %>% ggpairs()
amesHouse %>% dplyr::select(lSalePrice,GarageYrBlt,GarageCars,GarageArea) %>% ggpairs()
#The above variables all seem to have a good linear correlation with lSalePrice
#Keep going
amesHouse %>% dplyr::select(SalePrice,WoodDeckSF,OpenPorchSF,EnclosedPorch,X3SsnPorch,ScreenPorch,MiscVal)%>%
ggpairs()
amesHouse %>% dplyr::select(lSalePrice,WoodDeckSF,OpenPorchSF,EnclosedPorch,X3SsnPorch,ScreenPorch,MiscVal)%>%
ggpairs()
#Loading libraries needed
library(tidyverse)
library(ggplot2)
#Loading in Employee data
employeeData = read.csv("/Users/mingyang/Desktop/SMU/DoingDS_Fall2020/CaseStudy2DDS/CaseStudy2-data.csv",header = TRUE)
summary(employeeData)
#See which column has only unique value
sapply(employeeData,function(col) length(unique(col)))
#Delete column that has only one unique value
to.be.deleted = which(sapply(employeeData,function(col) length(unique(col))==1))
employeeData = employeeData[,-to.be.deleted]
#Convert some values into factors
cols.to.factor = c("Attrition","BusinessTravel","Department","EducationField","EnvironmentSatisfaction",
"Gender","JobInvolvement","JobLevel","JobRole","JobSatisfaction","MaritalStatus","NumCompaniesWorked",
"OverTime","PerformanceRating","RelationshipSatisfaction","StockOptionLevel","TrainingTimesLastYear",
"WorkLifeBalance")
employeeData[cols.to.factor] = lapply(employeeData[cols.to.factor],factor)
#Load in libraries
library(lattice)
library(caret)
library(mlbench)
#prepare training scheme
control = trainControl(method="repeatedcv", number=10, repeats=3)
#train the model
model = train(Attrition~.,data=employeeData,method="lvq",preProcess="scale", trControl=control)
#estimate variable importance
importance = varImp(model,scale=FALSE)
#summarize importance
print(importance)
#plot importance
plot(importance)
#Load NB libraries
library(e1071)
#select variables decided to predict Attrition
data.nb = employeeData %>% select(Attrition, OverTime, MonthlyIncome, TotalWorkingYears, YearsAtCompany, StockOptionLevel, MaritalStatus, JobLevel, YearsInCurrentRole, YearsWithCurrManager, Age, JobInvolvement, JobSatisfaction, JobRole, Department,Education, WorkLifeBalance, EnvironmentSatisfaction)
set.seed(12)
splitPercent = 0.80
trainIndex = sample(1:dim(data.nb)[1],round(splitPercent * dim(data.nb)[1]))
train.nb = data.nb[trainIndex,]
test.nb = data.nb[-trainIndex,]
model.nb = naiveBayes(Attrition~.,data=train.nb, laplace = 1)
predict.nb = predict(model.nb,test.nb)
table(predict.nb,test.nb$Attrition)
confusionMatrix(predict.nb,test.nb$Attrition)
#Load library to run stepwise regression method to choose an optimal simple model
library(MASS)
#Build the model with internel verfication
set.seed(24)
train.control <- trainControl(method = "cv", number = 10)
step.model = train(MonthlyIncome~., data=employeeData,
method="lmStepAIC",
trControl = train.control,
trace=FALSE)
#Model Accuracy
step.model$results
step.model$finalModel
summary(step.model$finalModel)
?sd
?pt
pt(0.95,49)
qt(0.95,49)
?qt
qt(0.975,473.85)
qnorm(0.975,13)
?qnorm
qnorm(0.975,0,1)
?pf
pt(1.06,1,280)
pt(5,1,280)
pf(1.06,1,280)
1- pf(1.06,1,280)
?pt
pt(2.84,14)
1-pt(2.84,14)
1-2*pt(2.84,14)
(1-pt(2.84,14))*2
qnorm(2.84,0,1)
?qnorm
qnorm(2.84)
pnorm(2.84)
1- pnorm(2.84)
2^(1.249-2.594*0.031)
pf(1.06,1,280)
qt(0.95,1000000000)
qnorm(0.95)
qt(0.95,100)
qt(0.95,30)
qt(0.025,30)
qt(0.025,30)
qnorm(0.025,30)
qnorm(0.025)
qt(0.025,100)
qt(0.025,1000000)
qt(0.025,10000000000)
qt(0.45,1000000000000)
qnorm(0.45)
qnorm(0.5)
qt(0.5,1000000000000)
qnorm(0.6)
qt(0.6,1000)
qt(0.6,100)
exp(0.1975)
9.381-8.667
0.714/9
0.079/0.619
pf(0.128,9,14)
1-pf(0.128,9,14)
1.99979-0.001126
0.0998499+0.0102828
1.99979-0.0001084
0.0998499+0.0303267
exp(1.999789181)
Exp(-0.001083732)
exp(-0.001083732)
exp(0.03032665)
231-7
?qt
qt(0.995,224)
0.200127253+0.00013768*2.598
0.200127253-0.00013768*2.598
qt(0.975,224)
1.998664+0.1101327*9.4+0.2001273*2
exp(3.424166)
1.998664+0.1101327*9.4+0.2001273*3
exp(3.634293)
exp(3.627926)
exp(3.640658)
0.010282784-0.030326651
(4+9-8.2)*10^08
sqrt(4.8*10^(-8))
qt(0.975,224)
-0.02004387+1.97*0.000219
-0.02004387-1.97*0.000219
0.714/5
9.381-9.667
9.381-8.667
0.1428/0.619
1-pf(0.231,5,14)
library(tidyverse)
library(ggplot2)
library(GGally)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/Applied Statistics/MSDS6372Project1")
# Directly import cleaned dataset and start from here
CarData = read.csv("CleanedCarData.csv")
# Convert factor variables
variables.to.factor = c("Make","Model","EngineFuelType","TransmissionType","DrivenWheels","MarketCategory","VehicleSize","VehicleStyle","Crossover","Diesel","Exotic","Luxury","HighPerformance","FactoryTuner","Performance","FlexFuel","Hatchback","Hybrid","N_A")
CarData[variables.to.factor] = lapply(CarData[variables.to.factor],factor)
summary(CarData)
# Plot agsint numeric variables
# CarData %>% select(MSRP,Year,EngineHP,EngineCylinders,NumberOfDoors,HighwayMPG,CityMPG,Popularity) %>% ggpairs()
CarData = CarData[,-10] #delete MarketCategory
######### Try Something else to split data ############
# First 842 are Models that only have 5 observations or less
ModelList = CarData%>% group_by(Model) %>% mutate(ModelCount = n()) %>% arrange(ModelCount)
#arrange(ModelList,desc(count))%>%print(n = Inf)
# Can only split train/test/validate set on Models that has 6 observations or more
ModelList = ModelList[,-27]
Not.Able.To.Split = ModelList[(1:842),]
Able.To.Split = ModelList[-(1:842),]
# Split Train, test, validate based on able to Train Data...
set.seed(111)
validate.set.index<-sample(1:dim(Able.To.Split)[1],1191,replace=F)
validate = Able.To.Split[validate.set.index,]
remains1 = Able.To.Split[-validate.set.index,]
set.seed(112)
test.index = sample(1:dim(remains1)[1],1191,replace=F)
test = remains1[test.index,]
train = remains1[-test.index,]
# Joining train set with dataset that been left out
train = bind_rows(train,Not.Able.To.Split)
dim(train)
str(train)
str(CarData)
# Use Forward variable selection method to select possible variables as predictors
########################################
# Try Forward selection model.##########
########################################
library(leaps)
library(olsrr)
########################################
# Try LASSO variable selection #########
########################################
library(glmnet)
#Dummy code categorical predictor variables
x <- model.matrix(MSRP~.,train)[,-1]
y <- train$MSRP
x
str(train)
cv.out=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
plot(cv.out)
# Look at the coefficient for best lambda
coef(cv.out, cv.out$lambda.min)
#Dummy code test set to see performance compare to other methods
xtest<-model.matrix(MSRP~.,test)[,-1]
ytest<-test$MSRP
# Look at the coefficient for best lambda
# coef(cv.out, cv.out$lambda.min)
# Compute the final lasso model
lasso.model = glmnet(x,y,alpha = 1,lambda = cv.out$lambda.min)
# See prediction
lasso.pred=predict(lasso.model ,newx=xtest)
head(lasso.pred)
# See test ASE
testMSE_LASSO<-mean((ytest-lasso.pred)^2)
testMSE_LASSO
#####################################################
# Compare Forward vs. Backward on Test set to LASSO #
#####################################################
# Test result
test.result = test$MSRP
str(test)
test = test[,-15] #delete MSRP for prediction
#Forward
forward.pred = predict(forward.regression,test)
# By looking at this model, it has selected following predictors:
# Make+Model+EngineFuelType+VehicleSize+VehicleStyle+Crossover+HighPerformance+TransmissionType+Exotic+Hatchback
forward.regression = lm(MSRP~Make+Model+EngineFuelType+VehicleSize+VehicleStyle+Crossover+HighPerformance+TransmissionType+Exotic+Hatchback,data=train)
#Forward
forward.pred = predict(forward.regression,test)
head(forward.pred)
testMSE_Forward<-mean((test.result-forward.pred)^2)
testMSE_Forward
# Predictor for backward elimination method based on lowest BIC value
# Make+Model+EngineFuelType+VehicleSize+Crossover+HighPerformance+Hybrid+VehicleStyle+Exotic
backward.regression = lm(MSRP~Make+Model+EngineFuelType+VehicleSize+Crossover+HighPerformance+Hybrid+VehicleStyle+Exotic,data=train)
#Backward test results
backward.pred = predict(backward.regression,test)
# See backward test ASE
testMSE_Backward<-mean((test.result-backward.pred)^2)
testMSE_Backward #46312425
coef(cv.out, cv.out$lambda.min)
# Look at the coefficient for best lambda
coefficients = coef(cv.out, cv.out$lambda.min)
head(coefficients)
# Check assumptions
lasso.model
# Check assumptions
ols_plot_cooksd_bar(lasso.model)
